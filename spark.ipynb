{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"HADOOP_INSTALL\"] = \"/home/hadoop/hadoop\"\n",
    "os.environ[\"HADOOP_HOME\"] = os.environ[\"HADOOP_INSTALL\"]\n",
    "os.environ[\"HADOOP_MAPRED_HOME\"] = os.environ[\"HADOOP_INSTALL\"]\n",
    "os.environ[\"HADOOP_COMMON_HOME\"] = os.environ[\"HADOOP_INSTALL\"]\n",
    "os.environ[\"HADOOP_HDFS_HOME\"] = os.environ[\"HADOOP_INSTALL\"]\n",
    "os.environ[\"HADOOP_YARN_HOME\"] = os.environ[\"HADOOP_INSTALL\"]\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = os.path.join(os.environ[\"HADOOP_INSTALL\"], \"/etc/hadoop\")\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/hadoop/spark\"\n",
    "sys.path.insert(0, os.path.join(os.environ[\"SPARK_HOME\"], \"python\"))\n",
    "sys.path.append(os.path.join(os.environ[\"SPARK_HOME\"], \"python/lib/py4j-0.10.9.2-src.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://192.168.121.62:4041\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HelloLines\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"1024M\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print(sc.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromHDFS(filePath):\n",
    "   try:\n",
    "      return spark.read.options(header='True').csv(filePath)\n",
    "   except Exception as e:\n",
    "      return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"hdfs:/datasets/spotify/tracks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda x: json.loads(x))\n",
    "dfp = rdd2.toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Statistics about songs duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 - Generate a table containing the minimum, average and maximum duration, in milliseconds, of the songs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+--------+\n",
      "|  0|234408.54976216817|10435467|\n",
      "+---+------------------+--------+\n",
      "+---+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregates = getDataFromHDFS('q1.1.csv')\n",
    "if aggregates == -1:\n",
    "    min = dfp.agg({ 'duration_ms' : 'min' })\n",
    "    avg = dfp.agg({ 'duration_ms' : 'avg' })\n",
    "    max = dfp.agg({ 'duration_ms' : 'max' })\n",
    "    aggregates = min.join(avg)\n",
    "    aggregates = aggregates.join(max)\n",
    "    aggregates.write.option(\"header\", True).csv('./q1.1.csv')\n",
    "aggregates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 - Compute the first and third quartiles (denoted Q1​ and Q3​), as well as the interquartile range (IRQ) (Q3​−Q1​)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 336:>                                                        (0 + 4) / 4]\r"
     ]
    }
   ],
   "source": [
    "quantiles = dfp.approxQuantile(\"duration_ms\", [0.25, 0.75], 0)\n",
    "q1, q3 = quantiles[0], quantiles[1]\n",
    "q1, q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 - Compute the set of songs with durations that are not outliers, as defined by the IQRR methodology. In other words, identify all songs with duration xx such that Q1 − 1.5 × IQR < x < Q3 + 1.5 × IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_treatment(df, factor=1.5):\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define the upper and lower bounds for outliers\n",
    "    lower_bound = q1 - factor * iqr\n",
    "    upper_bound = q3 + factor * iqr\n",
    "\n",
    "    df_not_outliers = df.filter((df[\"duration_ms\"] > lower_bound) & (df[\"duration_ms\"] < upper_bound))\n",
    "    df_outliers = df.subtract(df_not_outliers)\n",
    "\n",
    "    return df_not_outliers, df_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10200555"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not_outliers\n",
    "df_treated = iqr_outlier_treatment(dfp)\n",
    "df_not_outliers = df_treated[0]\n",
    "df_not_outliers.count()\n",
    "\n",
    "# not_outliers_aggregates = getDataFromHDFS('q1.3.csv')\n",
    "# if not_outliers_aggregates == -1:\n",
    "#     min = df_not_outliers.agg({ 'duration_ms' : 'min' })\n",
    "#     avg = df_not_outliers.agg({ 'duration_ms' : 'avg' })\n",
    "#     max = df_not_outliers.agg({ 'duration_ms' : 'max' })\n",
    "#     not_outliers_aggregates = min.join(avg)\n",
    "#     not_outliers_aggregates = not_outliers_aggregates.join(max)\n",
    "#     not_outliers_aggregates.write.option(\"header\", True).csv('./q1.3.csv')\n",
    "# not_outliers_aggregates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 - Using the IQRR methodology, how many songs would be considered outliers and removed from analysis? Generate a new table containing the minimum, average and maximum duration of the remaining songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+--------+\n",
      "|_c0|              _c1|     _c2|\n",
      "+---+-----------------+--------+\n",
      "|  0|371193.3242420833|10435467|\n",
      "+---+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# outliers\n",
    "df_outliers = df_treated[1]\n",
    "#df_outliers.count()\n",
    "\n",
    "outliers_aggregates = getDataFromHDFS('q1.4.csv')\n",
    "if outliers_aggregates == -1:\n",
    "    min = df_outliers.agg({ 'duration_ms' : 'min' })\n",
    "    avg = df_outliers.agg({ 'duration_ms' : 'avg' })\n",
    "    max = df_outliers.agg({ 'duration_ms' : 'max' })\n",
    "    outliers_aggregates = min.join(avg)\n",
    "    outliers_aggregates = aggregates.join(max)\n",
    "    outliers_aggregates.write.option(\"header\", True).csv('./q1.4.csv')\n",
    "outliers_aggregates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = sc.textFile(\"hdfs:/datasets/spotify/playlist.json\")\n",
    "rdd3 = rdd3.map(lambda x: json.loads(x))\n",
    "dfplaylists = rdd3.toDF()\n",
    "\n",
    "dfsuper = dfp.withColumnRenamed('pid', 'pid_playlist')\n",
    "dfsuper = dfsuper.join(dfplaylists, dfsuper.pid_playlist == dfplaylists.pid, 'left')\n",
    "#most popular artists by the number of playlists they appear in\n",
    "from pyspark.sql.functions import countDistinct, col, year, from_unixtime\n",
    "dfsuper = (dfsuper \\\n",
    "    .groupBy('artist_name', year(from_unixtime('modified_at')).alias('year')) \\\n",
    "    .agg(countDistinct('pid') \\\n",
    "    .alias('num_playlists')) \\\n",
    "    .orderBy(col('num_playlists').desc()))\n",
    "top_artists = [\"Drake\", \"Rihanna\", \"Kanye West\", \"The Weeknd\", \"Kendrick Lamar\"]\n",
    "top_artists_per_year = getDataFromHDFS('q2.csv')\n",
    "if top_artists_per_year == -1:\n",
    "    top_artists_per_year = dfsuper \\\n",
    "        .filter(col('artist_name').isin(top_artists))\n",
    "    top_artists_per_year.write.option(\"header\", True).csv('./q2.csv')\n",
    "drake_yoy =  top_artists_per_year.where('artist_name=\"Drake\"').toPandas()\n",
    "rihanna_yoy = top_artists_per_year.where('artist_name=\"Rihanna\"').toPandas()\n",
    "kendrick_yoy = top_artists_per_year.where('artist_name=\"Kendrick Lamar\"').toPandas()\n",
    "kanye_yoy = top_artists_per_year.where('artist_name=\"Kanye West\"').toPandas()\n",
    "weeknd_yoy = top_artists_per_year.where('artist_name=\"The Weeknd\"').toPandas()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(drake_yoy['year'], drake_yoy['num_playlists'])\n",
    "plt.plot(rihanna_yoy['year'], rihanna_yoy['num_playlists'])\n",
    "plt.plot(kendrick_yoy['year'], kendrick_yoy['num_playlists'])\n",
    "plt.plot(kanye_yoy['year'], kanye_yoy['num_playlists'])\n",
    "plt.plot(weeknd_yoy['year'], weeknd_yoy['num_playlists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Playlists's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is more common, playlists where there are many songs by the same artist or playlists with more diverse songs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-----+\n",
      "|pid|artist_name          |count|\n",
      "+---+---------------------+-----+\n",
      "|5  |Lady Gaga            |2    |\n",
      "|6  |Tame Impala          |1    |\n",
      "|14 |The Smashing Pumpkins|2    |\n",
      "|29 |Chance The Rapper    |1    |\n",
      "|34 |The Chainsmokers     |4    |\n",
      "|34 |FRENSHIP             |1    |\n",
      "|65 |Stryker Pose         |1    |\n",
      "|76 |The Wild Wild        |1    |\n",
      "|89 |REO Speedwagon       |1    |\n",
      "|89 |Deniece Williams     |1    |\n",
      "|90 |Ryan Bingham         |3    |\n",
      "|91 |Tony! Toni! Toné!    |2    |\n",
      "|91 |The Weeknd           |1    |\n",
      "|97 |The Lost Fingers     |1    |\n",
      "|104|CocoRosie            |1    |\n",
      "|106|2 Unlimited          |1    |\n",
      "|106|Avicii               |1    |\n",
      "|106|Afrojack             |1    |\n",
      "|112|M.I.A.               |1    |\n",
      "|121|Rihanna              |1    |\n",
      "+---+---------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# playlists com mais musicas do mesmo artista vs playlists com mais musicas de artistas variados\n",
    "# tem um atributo com num_artists (the total number of unique artists for the tracks in the playlist)\n",
    "\n",
    "# groupBy pid da playlist, pelo artista e vê qnts musicas esse artista tem na playlist\n",
    "\n",
    "group_cols = [\"pid\", \"artist_name\"]\n",
    "df_grouped = dfp.groupBy(group_cols).count().show(truncate=False)\n",
    "\n",
    "# pegar o top artista mais frequente em cada playlist \n",
    "\n",
    "\n",
    "# prevalence = total de musicas/total de musicas do artista mais frequente\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
